---
title: "Assignment 2"
author: Group 20, Aliya Mosha (s2206786), Saioa Galvin (s2516907), Hugh Graham (s2318382),
  (... words)
date: "2025-10-29"
output:
  html_document: default
  pdf_document: default
---

```{r load_packages, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(afex))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(viridis))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(patchwork))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(cv))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(fitdistrplus))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(quantreg))

theme_set(
  theme_bw() +
    theme(
      plot.title = element_text(size = 20, hjust = 0.5),
      axis.title.x = element_text(size = 16),
      axis.title.y = element_text(size = 16),
      axis.text = element_text(size = 13),
      legend.title = element_text(size = 14),
      legend.text = element_text(size = 12),
      plot.caption = element_text(size = 11, hjust = 1),
      plot.subtitle = element_text(size = 14, face = "italic")
    )
)
```

```{r reading_code, code=readLines("code.R"), eval=FALSE, echo=FALSE, message=FALSE}
source("code.R")
```

```{r data_wrangling, echo = FALSE, message = FALSE, fig.width=20, fig.height=40, fig.align='center'}
# --- data wrangling ---
data <- read_excel("SCS_BAC_and_BrAC_split_TOP.xlsx")
data$sex <- as.factor(data$Sex)
data$beta60 <- data$`Beta60 (g/kg/h)`
data$weight <- data$`Weight (kg)`
data$height <- data$`Height (cm)`
data$age <- data$`Age (years)`
data$beta <- -data$beta60
```

# Executive Summary

# Task 1

## Exploratory Data Analysis

In order to understand and evaluate the performance of the $\beta$ elimination rate, we first examine various plots to visualise how the rate is influenced by certain characteristics. The characteristics of interest are:

-   `weight`: the weight (in kg) of a given individual;

-   `height`: the height (in cm) of a given individual;

-   `age`: the age (in years) of a given individual;

-   `sex`: the sex of a given individual.

These are each plotted against the $\beta$ elimination rate. Intuitively a larger $\beta$ value corresponds to faster elimination of alcohol from the blood stream. Figures 1-4 below explore these relationships.

```{r eda, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
# --- beta EDA ---

# beta vs weight
weight_plot <- ggplot(data, aes(x=weight, y=beta, colour = sex)) +
  geom_point() +
  geom_smooth(method="lm", color="navy") +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  labs(title="Figure 1: β vs Weight", x="Weight (kg)", y="β Elimination Rate (g/kg/h)")

# beta vs height
height_plot <- ggplot(data, aes(x=height, y=beta, colour = sex)) +
  geom_point() +
  geom_smooth(method="lm", color="navy") +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  labs(title="Figure 2: β vs Height", x="Weight (cm)", y="β Elimination Rate (g/kg/h)")

# beta vs age
age_plot <- ggplot(data, aes(x=age, y=beta, colour = sex)) +
  geom_point() +
  geom_smooth(method="lm", color="navy") +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  labs(title="Figure 3: β vs Age", x="Age (years)", y="β Elimination Rate (g/kg/h)")

# beta vs gender
sex_plot <- ggplot(data, aes(x = sex, y = beta60,
                             fill = sex)) +
  geom_violin(alpha = 0.8) +
  geom_boxplot(width = 0.2, color = "navy", alpha = 0.7) +
  scale_fill_manual(values = c("lightblue", "steelblue")) +
  labs(
    title = "Figure 4: β vs Gender",
    x = "Gender",
    y = "β Elimination Rate (g/kg/h)"
  ) +
  guides(fill = "none") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

(weight_plot + height_plot) /
  (age_plot + sex_plot) /
  plot_layout(ncol = 1) +
  plot_annotation(
    title = "β vs Characteristics Plots",
    theme = theme(plot.title = element_text(size = 16, face = "bold"))
  )
```

From Figures 1-4, we can deduce the following:

-   as weight increases the elimination rate decreases linearly;

-   similarly, as height increases the elimination rate decreases linearly;

-   the majority of age data is scattered between 20-30, however there is a reasonably constant spread of values, suggesting age is less influential on alcohol elimination;

-   there is a clear difference in elimination rate between genders, with males typically obtaining higher values.

To further enhance our investigation into the effect each of these characteristics has on the elimination rate, we can view the following correlation plot, which calculates the pairwise correlations between our variables.

```{r correlations, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
library(dplyr)

# pairwise correlations between characteristics and beta
corr <- data %>%
  dplyr::select(beta, weight, age, height) %>%
  cor(use = "pairwise.complete.obs") %>%
  round(3)

kable(corr, digits = 3,
      caption = "Pairwise Correlations Between Characteristics and Beta")
```

From this output, we can see that weight and height have significant correlations with the $\beta$ elimination rate, with respective correlations of -0.356 and -0.410. This suggests that these characteristics play a crucial role in determining the rate at which alcohol is eliminated from the blood stream. As expected, there is a low correlation between age and elimination rate.

Due to the clear relationships between $\beta$ and characteristics of the tested individuals, it is worth considering approaches in which these factors are incorporated to accurately predict the rate at which alcohol is eliminated from the blood stream.

## Modelling Beta

### Finding Distribution Method

An issue with creating a distribution from the $\beta$ elimination rate values given is that we only have 100 data points. Therefore the distribution is very dependent on not many values. We propose instead investigating if beta_60 follows a standard distribution. First, we will examine the general spread of beta_60 values given in the following histogram.

```{r density_plot, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

density_plot <- ggplot(data, aes(x = beta)) +
  geom_histogram(aes(y = after_stat(density)),
                 binwidth = 0.005,
                 fill = "navy",
                 alpha = 0.55) +
  geom_density(color = "navy", 
               size = 1) +
  geom_vline(aes(xintercept=mean(beta)),
             linetype = "dashed",
             color = "navy",
             size = 1) +
  geom_vline(aes(xintercept=quantile(beta, 0.025)),
             linetype = "dotted",
             color = "navy",
             size = 1) +
  geom_vline(aes(xintercept=quantile(beta, 0.975)),
             linetype = "dotted",
             color = "navy",
             size = 1) +
  labs(x = expression(""*beta), y = "Density", title = expression("Distribution of "*beta))

density_plot
```

We have seen from exploratory data analysis that the rate at which alcohol density in the blood decreases is dependent on a range of variables given in the data. As Sex is the only discrete variable, we can split the data in two to see how $\beta$, the alcohol elimination rate, is distributed for males and females in the dataset given.

```{r sex_density_plot, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
# compute group statistics
stats <- data %>%
  group_by(sex) %>%
  summarize(
    mean = mean(beta),
    q025 = quantile(beta, 0.025),
    q975 = quantile(beta, 0.975)
  )

# plot
sex_density_plot <- ggplot(data, aes(x = beta, color = sex, fill = sex)) +
  geom_histogram(aes(y = after_stat(density)),
                 binwidth = 0.005, alpha = 0.4, position = "identity") +
  geom_density(size = 1, alpha = 0) +
  geom_vline(data = stats, aes(xintercept = mean, color = sex),
             linetype = "dashed", size = 1) +
  geom_vline(data = stats, aes(xintercept = q025, color = sex),
             linetype = "dotted", size = 1) +
  geom_vline(data = stats, aes(xintercept = q975, color = sex),
             linetype = "dotted", size = 1) +
  scale_color_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  scale_fill_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  labs(x = expression(""*beta), y = "Density", title = expression("Distribution of "*beta*" by Sex"))

sex_density_plot
```

These visualisations can point us towards a few different distributions. We can analyse how well the data fits the distributions in the following plots.

#### Residual Plots of Fitted Distributions

```{r normal, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
normal_fit <- fitdist(data$beta, distr = "norm", method = "mle")
beta_fit <- fitdist(data$beta, distr = "beta", method = "mle")
gamma_fit <- fitdist(data$beta, distr = "gamma", method = "mle")

par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))
plot.legend <- c("Normal", "Beta", "Gamma")
denscomp(list(normal_fit, beta_fit, gamma_fit), legendtext = plot.legend)
qqcomp(list(normal_fit, beta_fit, gamma_fit), legendtext = plot.legend)
cdfcomp(list(normal_fit, beta_fit, gamma_fit), legendtext = plot.legend)
ppcomp(list(normal_fit, beta_fit, gamma_fit), legendtext = plot.legend)
```

#### Normal Distribution

-   `Empirical and Theoretical Densities`: The theoretical peak value is skewed compared to the empirical peak, and has lower density.

-   `Q-Q plot`: Lack-of-fit observed at distribution tails. The left tail is heavy while the right tail is light.

-   `Empirical and Theoretical CDFs`: Poor fit at central values of the distribution.

-   `P-P plot`: Lack-of-fit at the distribution centre, as the central values deviate from the linear relationship.

#### Beta Distribution

-   `Empirical and Theoretical Densities`: Improved fit of peak is observed, while still not completely aligned.

-   `Q-Q plot`: Points are randomly distributed above and below the general linear trend, with outliers at the lower tail.

-   `Empirical and Theoretical CDFs`: Improved fit at distribution centre compared to normal.

-   `P-P plot`: Improved fit at distribution centre compared to normal.

#### Gamma Distribution

-   `Empirical and Theoretical Densities`: Best fit of peak of the analysed distributions.

-   `Q-Q plot`: Points are randomly distributed above and below the general linear trend across all quantiles.

-   `Empirical and Theoretical CDFs`: Best fit of theoretical distribution to data.

-   `P-P plot`: Majority of points lie on fitted line.

This is an improved fit compared to the normal distribution, as the empirical and theoretical densities are more aligned, and ... A similar distribution is the gamma distribution.

```{r gamma, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
gamma_shape <- gamma_fit$estimate[[1]]
gamma_rate <- gamma_fit$estimate[[2]]
q025 <- qgamma(0.025, gamma_shape, gamma_rate)
```

The 2.5% quantile in the gamma distribution of $\beta$ is 0.1257847.

Considering that Sex is a factor variable, we can find the distributions of beta_60 dependent on whether the suspect is male of female.

```{r gamma_sex, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

m_data <- data %>% filter(Sex == "male")
m_gamma_fit <- fitdist(m_data$beta, distr = "gamma", method = "mle")
m_gamma_shape <- m_gamma_fit$estimate[[1]]
m_gamma_rate <- m_gamma_fit$estimate[[2]]
m_quantiles <- qgamma(c(0.025, 0.5, 0.975), m_gamma_shape, m_gamma_rate)

f_data <- data %>% filter(Sex == "female")
f_gamma_fit <- fitdist(f_data$beta, distr = "gamma", method = "mle")
f_gamma_shape <- f_gamma_fit$estimate[[1]]
f_gamma_rate <- f_gamma_fit$estimate[[2]]
f_quantiles <- qgamma(c(0.025, 0.5, 0.975), f_gamma_shape, f_gamma_rate)

gamma_sex_df <- data.frame(
  x = data$beta,
  male_density   = dgamma(data$beta, shape = m_gamma_shape, rate = m_gamma_rate),
  female_density = dgamma(data$beta, shape = f_gamma_shape, rate = f_gamma_rate)
)

gamma_long <- gamma_sex_df %>%
  pivot_longer(cols = c(male_density, female_density),
               names_to = "Sex",
               values_to = "density") %>%
  mutate(Sex = ifelse(Sex == "male_density", "male", "female"))

stats_gamma <- data.frame(
  Sex = rep(c("male", "female"), each = 3),
  Quantile = rep(c("q025", "q50", "q975"), times = 2),
  value = c(m_quantiles, f_quantiles)
)

# plot
sex_gamma_plot <- ggplot(data, aes(x = beta, color = Sex, fill = Sex)) +
  geom_histogram(aes(y = after_stat(density)),
                 binwidth = 0.005, alpha = 0.4, position = "identity") +
  geom_line(data = gamma_long,
            aes(x = x, y = density, color = Sex),
            size = 1.2) +
  geom_vline(
    data = stats_gamma,
    aes(xintercept = value, color = Sex, linetype = Quantile),
    size = 1
  ) +
  scale_color_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  scale_fill_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  scale_linetype_manual(
    values = c("q025" = "dotted", "q50" = "dashed", "q975" = "dotted"),
    labels = c("2.5%", "50%", "97.5%")
  ) +
  labs(
    x = expression(beta),
    y = "Density",
    title = expression("Gamma Distributions of "*beta*" by Sex"),
    linetype = "Quantile"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14, face = "bold")
  )

sex_gamma_plot
```

The 2.5% quantile in the gamma distribution for males is 0.1219521, and for females it is 0.1430605.

### Linear Model Method

Instead of fitting a distribution, we can create a linear model. This creates a distribution for $\beta$ given a range of information about the suspect, whether this information is in the form of discrete or continuous form. This is more useful than the method that finds a different beta distribution for males and females, as it is not possible to do the same for continuous information such as age. Therefore the previous methods don't make the most of all the information given.

We can create the following model, where $\beta_j$ represent the coefficients for $j \in \{0, ..., 4\}$ to model $Y_i$, the $i$ datapoints of $\beta$:

$$
\begin{aligned}
\text{linear model}: \quad 
Y_i &= \beta_0 
+ \beta_1\text{weight}_i 
+ \beta_2\text{age}_i 
+ \beta_3\text{height}_i 
+ \beta_4\text{sex}_i
+ \epsilon_i, \\
\epsilon_i &\overset{\mathrm{iid}}\sim \mathcal{N}(0, \sigma^2).
\end{aligned}
$$

#### Residual Plots for Linear Model

```{r modelling_beta, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}
# --- linear modelling beta 60 attempt ---

# model incorporating all characteristics
lm_model <- lm(beta ~ weight + age + height + sex, data = data)

# Residual plots
par(mfrow = c(2,2))
plot(lm_model)
```

-   `Residual vs Fitted`: There is a change of variance with mean, so the constant variance assumption is slightly violated. Unfortunately there is little data points to establish if this is an important violation.

-   `Q-Q Residuals`: The ordered standardised residuals are plotted against quantiles of a standard normal. Lack-of-fit observed at distribution tails. The left tail is heavy while the right tail is light.

-   `Scale-Location`: We have random variation around the mean, so there is no violation of the constant variation assumption.

-   `Residuals vs Leverage`: This plot gives us Cook’s distance, which measures the change in all model fitted values on omission of the data point in question. From the plot we can see there are no outliers, so there aren't any highly influential points in our data.

To try to resolve these violations of the assumptions on residuals, we can create an alternative linear model. Given that there is a quadratic shape in the `Residuals vs Fitted` graph, we create the following linear model.

$$
\begin{aligned}
\text{square root linear model}: \quad 
\sqrt{Y_i} &= \beta_0 
+ \beta_1\text{weight}_i 
+ \beta_2\text{age}_i 
+ \beta_3\text{height}_i 
+ \beta_4\text{sex}_i
+ \epsilon_i, \\
\epsilon_i &\overset{\mathrm{iid}}\sim \mathcal{N}(0, \sigma^2).
\end{aligned}
$$

We get the following residual graphs.

#### Residual Plots for Square Root Linear Model

```{r lm, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# Try modelling square root of beta (residual plots indicate a slight quadratic mean-variance relationship)

sqrt_lm_model <- lm(sqrt(beta) ~ weight + age + height + sex, data = data)

# Residual plots
par(mfrow = c(2,2))
plot(sqrt_lm_model)
```

The `Q-Q Residuals` plot is improved, however there is only marginal change in the `Residuals vs Fitted` plot. Therefore we explore alternative methods.

### Quantile Linear Model Method

The biggest issue with the linear model above for use in our project is that it's aim is to find the conditional mean function, $E(\beta | x)$, where $x$ represents the explanatory variables of the model. The aim of our analysis is to find the 2.5% quantile of $\beta$. It is more accurate to use quantile regression. We use the same linear model as above.

```{r comparing_rq, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# Create predicted values
pred_data <- data

# quantiles for lm
resid_q025 <- quantile(residuals(lm_model), probs = 0.025)
pred_data$lm_pred <- predict(lm_model)
pred_data$lm_q025 <- pred_data$lm_pred + resid_q025

# using quantile regression instead
rq_model <- rq(beta ~ weight + age + height + sex, data = data, tau = 0.025)
pred_data$rq_pred <- predict(rq_model)

# Combine into a long format for ggplot
plot_data <- pred_data %>%
  tidyr::pivot_longer(cols = c(lm_q025, rq_pred),
                      names_to = "model",
                      values_to = "predicted_beta")

# Plot
quantile_v_lm_plot <- ggplot(plot_data, aes(x = beta, y = predicted_beta, color = model)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(
    title = expression("Comparing Models for the 2.5% Quantile for "*beta),
    x = expression("Actual "*beta),
    y = expression("Predicted "*beta),
    color = "Model Type"
  ) +
  scale_color_manual(values = c("lm_q025" = "firebrick", "rq_pred" = "forestgreen"),
                     labels = c("Linear Regression", "Quantile Regression"))

quantile_v_lm_plot
```

While it may look like taking the 2.5% quantile of the linear model, and using the quantile regression model produce very similar results, the methods are different. To find the 2.5% quantile of the linear model, we find the 2.5% quantile of the residuals, and add that onto $E(\beta | x)$ predicted by our model. This assumes homoscedaticity, that the residuals are independent of predictors, and we have shifted the line uniformly, without taking into account how residual quantile could change across the data. Our quantile regression method does not have a homoscedaticity assumption, which is more reasonable, especially as the residual plots of our linear model are questionable in upholding the homoscedaticity assumption.

## Task 2

We will compare the performance of our different approaches outlined in Task 1 with the following case study.

A 70 year old female (weight: 70kg, height: 160cm) is arrested after being stopped by the police while driving. She provides a blood sample to the police 2 hours after her arrest which gives a reading of Ct = 0.15g/kg (i.e. grams of alcohol per kilogram of blood). The legal limit is x = 0.47g/kg. The police wish to charge her with the criminal offence of driving while over the legal limit.

We can find the $2.5%$ quantile of the different beta distributions.

```{r task_2, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# setup from question
test_person <- data.frame(weight = 70, height = 160, age = 70, sex = "female")
Ct <- 0.15
t  <- 2

# empirical quantiles for Beta60 (population approach)
beta_pop <- quantile(data$beta, probs = c(0.025, 0.5, 0.975))

# C0 values using population quantiles
C0_pop <- Ct + beta_pop * t

# gamma fitted whole population distribution
gamma_quantiles <- qgamma(c(0.025, 0.5, 0.975), gamma_shape, gamma_rate)
C0_gamma <- Ct + gamma_quantiles * t

# gamma fitted to males
m_gamma_quantiles <- qgamma(c(0.025, 0.5, 0.975), m_gamma_shape, m_gamma_rate)
C0_gamma_m <- Ct + m_gamma_quantiles * t

# gamma fitted to females
f_gamma_quantiles <- qgamma(c(0.025, 0.5, 0.975), f_gamma_shape, f_gamma_rate)
C0_gamma_f <- Ct + f_gamma_quantiles * t

# predicted Beta using regression model
lm_pred_vals <- predict(lm_model, newdata = test_person, interval = "prediction", level = 0.95)

# C0 values from regression model
beta_pred_lm <- as.numeric(lm_pred_vals)
names(beta_pred_lm) <- c("Fitted", "Lower (PI 2.5%)", "Upper (PI 97.5%)")
C0_lm <- Ct + beta_pred_lm * t

# predicted beta using quantile regression model
rq_pred_vals <- predict(rq_model, newdata = test_person, interval = "confidence", level = 0.95)
C0_rq <- Ct + rq_pred_vals * t

# combine results into one comparison table 
results_table <- tibble(
  Approach = c("Population (empirical quantiles)", "Gamma Fitted", "Male Gamma Fitted", "Female Gamma Fitted", "Linear Regression", "Quantile Regression"),
  Lower_2.5 = c(C0_pop[1], C0_gamma[1], C0_gamma_m[1], C0_gamma_f[1], C0_lm[2], C0_rq[2]),  # note ordering: lwr=2nd col in pred
  Central   = c(C0_pop[2], C0_gamma[2], C0_gamma_m[2], C0_gamma_f[2], C0_lm[1], C0_rq[1]),
  Upper_97.5 = c(C0_pop[3], C0_gamma[3], C0_gamma_m[3], C0_gamma_f[3], C0_lm[3], C0_rq[3])
)

kable(results_table, digits = 3,
      col.names = c("Approach", "Lower (2.5%)", "Central", "Upper (97.5%)"),
      caption = "Comparison of estimated C₀ values for the various approaches")
```

## Task 3

### Finding $V_d$

If it is too late for a blood or breath test to predict accurate results for $C_0$, but there is eyewitness evidence measuring the quantity of alcohol consumed, the Widmark's equation can help to calculate the blood alcohol concentration $t$ hours after drinking ($C_t$). The validity of this estimate is dependent on the reliability of the eyewitness' testimony, however this analysis can be combined with other evidence to support a case. Widmark's equation can be written as

$$
C_t = \frac{A}{\text{Weight} \times V_d} - \beta t,
$$

where $A$ is the observed does of alcohol consumed, $\text{Weight}$ is the weight of the individual, and $V_d$ is a parameter known as the volume of distribution. Rearranging this equation we find

$$
C_0 = C_t +\beta_t = \frac{A}{\text{Weight} \times V_d},
$$

which in turn implies

$$
V_d = \frac{A}{\text{Weight} \times C_0}.
$$

Hence, given we are provided the data for $A$, $\text{Weight}$, and $C_0$, we can calculate $V_d$ using the above equation.

### Exploratory Data Analysis

Similar to our approach in analysing the effectiveness of the $\beta$ elimination rate, we can investigate the relationships between $V_d$ and characteristics of individuals (weight, height, age, and sex). It is also worth investigating the distribution of $V_d$ values across our sample.

Figures 5-9 help us visualise these relationships.

```{r task_3, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# define A, Co, Vd
data$A <- data$`Amount of Alcohol Consumed (g)`
data$Co <- data$`Co (g/Kg)`
data$Vd <- data$A/(data$Co *data$weight)

# view summary and quantiles of Vd
#summary(data$Vd)
#quantile(data$Vd, probs = c(0.025, 0.5, 0.975))

# histogram of Vd
ggplot(data, aes(x = Vd)) +
  geom_histogram(bins = 20, colour = "navy", fill = "steelblue") +
  labs(title = "Figure 5: Distribution of Volume of Distribution (Vd)",
       x = "Vd (L/kg)", y = "Count")

# Vd vs weight
weight_plot2 <- ggplot(data, aes(x = weight, y = Vd, colour = sex)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "navy") +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  labs(title = "Figure 6: Vd vs Weight", x = "Weight (kg)", y = "Vd (L/kg)")

# Vd vs height
height_plot2 <- ggplot(data, aes(x = height, y = Vd, colour = sex)) +
  geom_point() +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  geom_smooth(method = "lm", colour = "navy") +
  labs(title = "Figure 7: Vd vs Height", x = "Height (cm)", y = "Vd (L/kg)")

# Vd vs age
age_plot2 <- ggplot(data, aes(x = age, y = Vd, colour = sex)) +
  geom_point() +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  geom_smooth(method = "lm", colour = "navy") +
  labs(title = "Figure 8: Vd vs Age", x = "Age (years)", y = "Vd (L/kg)")

# Vd vs gender
sex_plot2 <- ggplot(data, aes(x = sex, y = Vd,
                             fill = sex)) +
  geom_violin(alpha = 0.8) +
  geom_boxplot(width = 0.2, color = "navy", alpha = 0.7) +
  scale_fill_manual(values = c("lightblue", "steelblue")) +
  labs(
    title = "Figure 9: Vd vs Gender",
    x = "Gender",
    y = "Vd (L/kg)"
  ) +
  guides(fill = "none") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

(weight_plot2 + height_plot2) /
  (age_plot2 + sex_plot2) /
  plot_layout(ncol = 1) +
  plot_annotation(
    title = "Vd Characteristics Plots",
    theme = theme(plot.title = element_text(size = 16, face = "bold"))
  )

```

From Figure 5, we can see that the majority of $V_d$ values lie around 0.65, in a roughly normally distributed pattern. There appears to be one particular outlier, with a $V_d$ value of around 1.2, which may be worth investigating further.

Figures 6-9 highlight the following relationships:

-   $V_d$ shows a very slight negative trend as weight increases;

-   $V_d$ appears constant across the range of heights;

-   $V_d$ appears to decrease with age, although again the majority of the data lies between ages of 20-30, so general conclusions are hard to draw from the sample;

-   $V_d$ appears constant across both genders.

The above findings suggest that $V_d$ seems to differ little across various characteristics of the individual. This suggests $V_d$ is a more generalised approach compared to the $\beta$ elimination rate.

It is also worth considering how the two rates are correlated, as independence is assumed between $\beta$ and $V_d$. Performing a correlation test between the two can help to deduce whether this assumption is upheld. Further, Figure 10 helps to visualise the relationship between $\beta$ and $V_d$.

```{r task_3 correlation, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# Test correlation to investigate independent assumption
cor.test(data$beta, data$Vd, use = "complete.obs")


# View quantiles of each coefficient for comparison
beta_range <- quantile(data$beta, probs = c(0.025, 0.975))
Vd_range   <- quantile(data$Vd, probs = c(0.025, 0.975))

# Scatter plot between beta and V_d
ggplot(data, aes(x = beta, y = Vd, colour = sex)) +
  geom_point() +
  scale_colour_manual(values = c("male" = "steelblue", "female" = "lightblue")) +
  geom_smooth(method = "lm", color = "navy") +
  labs(
    title = "Figure 10: Relationship between β and Vd",
    subtitle = paste("Correlation =", round(cor(data$beta, data$Vd, use = "complete.obs"), 3)),
    x = "β elimination rate (g/kg/h)",
    y = "Vd (L/kg)"
  )

```

From the correlation test, we find that there is an observed correlation of -0.404, and the null hypothesis that the true correlation is equal to zero, i.e. the two measures are independent, can be confidently rejected as there is a corresponding p-value of $3.122\times10^{-5}$.

Figure 10 further highlights this clear relationship between the two measures, and hence the independence assumption appears to be violated.

#### **Advantages of Current Method**

-   Simplicity: Easy to implement and explain in court
-   Conservative: Using the 97.5th percentiles provides a "benefit of the doubt" to defendants
-   Standardised: Same approach across all cases ensures consistency
-   Transparent: Clear, reproducible methodology

#### **Limitations of Current Method**

The current forensic method assumes independence between $\beta$ and $V_d$ when calculating the range for $C_t$. However, a Pearson's product-moment correlation analysis reveals a statistically significant negative correlation between these two parameters (correlation coefficient = -0.4036489, p-value = 3.122e-05 \< 0.05). This finding directly contradicts the independence assumption underlying the current approach.

Although the official forensic procedure specifies using the 97.5th percentile for both $\beta$ and $V_d$, this convention is based on policy rather than mathematical reasoning. Forensic laboratories apply the same "upper percentile rule" across all parameters to maintain consistency and to err on the side of caution, as using higher parameter values for $\beta$ and $V_d$ generally produces lower blood alcohol estimates. Mathematically Widmark's equation shows that $C_t$ decreases as $\beta$ and $V_d$ both increase, thus the maximum possible value of $C_t$ would occur for low $\beta$ and low $V_d$ values (their 2.5th percentiles). Regardless of which tail is used, the critical statistical issue with the current method is that it assumes that $\beta$ and $V_d$ are independent, when our analysis shows that $\beta$ and $V_d$ have a significant negative correlation.

Assuming independence allows forensic analysts to combine their most extreme values (e.g. highest $\beta$ with highest $V_d$) even though such an extreme combination almost never occurs in practice. This may produce inaccurate $C_t$ estimates, exaggerating how high a person's blood alcohol concentration might have been at the time of interest or significantly underestimating. In statistical terms, the current approach treats the joint distribution of $(\beta, V_d)$ as the product of their marginal distributions, when in reality the joint distribution should account for their negative dependence structure.

```{r joint_dist, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# Visualize the joint distribution

ggplot(data, aes(x = beta, y = Vd)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_density_2d(color = "navy") +
  # Add the marginal 97.5th percentiles
  geom_vline(xintercept = quantile(data$beta, 0.975, na.rm = TRUE), 
             linetype = "dashed", color = "red", linewidth = 1) +
  geom_hline(yintercept = quantile(data$Vd, 0.975, na.rm = TRUE), 
             linetype = "dashed", color = "red", linewidth = 1) +
  labs(
    title = "Joint Distribution of β and Vd",
    subtitle = "Red lines show marginal 97.5th percentiles",
    x = "β (g/kg/h)",
    y = "Vd (L/kg)"
  ) +
  annotate("text", 
           x = quantile(data$beta, 0.975, na.rm = TRUE), 
           y = min(data$Vd, na.rm = TRUE),
           label = "97.5th percentile β", 
           hjust = -0.1, color = "red")


```

The above plot of the joint distribution between $\beta$ and $V_d$ shows that there are no points in the top-right corner where both parameters are at their 97.5th marginal quantile simultaneously.

#### **Potential Alternative Methods**

1.  Use the empirical joint distribution of $(\beta, V_d)$ from the data
2.  Model the correlation structure explicitly (e.g. through the use of a linear regression model)
3.  Bayesian approach with prior distributions for $(\beta, V_d)$ specified and incorporated in the calculation (use eye-witness testimony as your "data" in order to calculate the posterior distribution)

#### **Alternative 1: Empirical Joint Distribution**

```{r emp_joint_dist, echo = FALSE, message = FALSE, warning=FALSE, fig.width=20, fig.height=10, fig.align='center'}

# Test person (from task 2)
A <- mean(data$A) # Chose this kinda randomly but made the most sense to me 
weight <- 70
t <- 2

# Calculate Ct using empirical joint distribution
data$Ct_joint <- (A / (weight * data$Vd)) - data$beta * t

# Compute the quantiles of C_t
quantile(data$Ct_joint, probs = c(0.025, 0.5, 0.975), na.rm = TRUE)

# Current (independent) approach
beta_ind <- quantile(data$beta, 0.975, na.rm = TRUE)
Vd_ind   <- quantile(data$Vd, 0.975, na.rm = TRUE)
Ct_independent <- (A / (weight * Vd_ind)) - beta_ind * t

# Table comparison
results_compare <- tibble(
  Method = c("Empirical joint (β,Vd)", "Independent 97.5th percentiles"),
  Lower_2.5 = c(round(quantile(data$Ct_joint, 0.025, na.rm = TRUE), 3), ""),
  Median     = c(round(quantile(data$Ct_joint, 0.5, na.rm = TRUE), 3), ""),
  Upper_97.5 = c(round(quantile(data$Ct_joint, 0.975, na.rm = TRUE), 3), 
                 round(Ct_independent, 3))
)

kable(results_compare, align = "lccc",
      caption = "Comparison of Empirical Joint vs Independent Ct")

```

The empirical joint $C_t$ distribution represents the upper and lower bounds of plausible blood alcohol concentrations for an individual with weight 70kg, who consumed the mean grams of alcohol from the sample and was tested 2 hours later.

As seen from the table above this resulted in a range (0.659, 1.455), compared to $C_t$ when assuming independence of $\beta$ and $V_d$ which gave a value of 0.497 which is outside the range of plausible values computed using the joint distribution. This highlights the idea that the current method may be too conservative, resulting in underestimated values of the actual blood alcohol levels of a person at the time of interest.

#### **Alternative 2: Linear Regression**

# Code Appendix

```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```
